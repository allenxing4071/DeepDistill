"""
DeepDistill ä¸»ç®¡çº¿ç¼–æ’
åè°ƒ 6 å±‚å¤„ç†æµç¨‹ï¼šè¾“å…¥ â†’ å†…å®¹å¤„ç† â†’ è§†é¢‘åˆ†æ â†’ AI æç‚¼ â†’ èåˆè¾“å‡º â†’ çŸ¥è¯†ç®¡ç†

æ ¸å¿ƒè®¾è®¡ï¼š
- æ¯ä¸€å±‚çš„è¾“å‡ºæ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œå±‚é—´é€šè¿‡ PipelineResult ä¼ é€’
- æ’ä»¶åŒ–ï¼šæ¯ä¸ªå¤„ç†å™¨å®ç°ç»Ÿä¸€æ¥å£ï¼Œå¯ç‹¬ç«‹æ›¿æ¢
- æ¸è¿›å¢å¼ºï¼šMVP åªéœ€ Layer 1-2-4-5
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

from .config import cfg

logger = logging.getLogger("deepdistill.pipeline")


@dataclass
class ProcessingResult:
    """ç®¡çº¿å¤„ç†ç»“æœ"""
    source_path: str
    source_type: str  # video/audio/image/document/webpage
    filename: str

    # Layer 2: æå–çš„æ–‡æœ¬
    extracted_text: str = ""

    # Layer 3: è§†é¢‘åˆ†æï¼ˆå¯é€‰ï¼‰
    video_analysis: dict | None = None

    # Layer 4: AI æç‚¼ç»“æœ
    ai_result: dict | None = None

    # Layer 5: è¾“å‡ºè·¯å¾„
    output_path: str = ""

    # å…ƒæ•°æ®
    processing_time_sec: float = 0.0
    created_at: str = ""
    errors: list[str] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "source_path": self.source_path,
            "source_type": self.source_type,
            "filename": self.filename,
            "extracted_text_length": len(self.extracted_text),
            "has_video_analysis": self.video_analysis is not None,
            "ai_result": self.ai_result,
            "output_path": self.output_path,
            "processing_time_sec": self.processing_time_sec,
            "created_at": self.created_at,
            "errors": self.errors,
        }


class Pipeline:
    """ä¸»ç®¡çº¿ï¼šåè°ƒå„å±‚å¤„ç†å™¨"""

    def __init__(self, output_dir: Path | None = None, output_format: str | None = None):
        self.output_dir = output_dir or cfg.OUTPUT_DIR
        self.output_format = output_format or cfg.OUTPUT_FORMAT
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def process(self, file_path: Path) -> ProcessingResult | None:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ç»“æœ"""
        import time
        start = time.time()

        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†: {file_path.name}")

        # Layer 1: è¾“å…¥å±‚ â€” æ ¼å¼è¯†åˆ«
        source_type = self._identify_type(file_path)
        if not source_type:
            logger.warning(f"âš ï¸  ä¸æ”¯æŒçš„æ ¼å¼: {file_path.suffix}")
            return None

        result = ProcessingResult(
            source_path=str(file_path),
            source_type=source_type,
            filename=file_path.name,
            created_at=datetime.now(timezone.utc).isoformat(),
        )

        # Layer 2: å†…å®¹å¤„ç†å±‚ â€” æ–‡æœ¬æå–
        try:
            result.extracted_text = self._extract_content(file_path, source_type)
            logger.info(f"  ğŸ“ æå–æ–‡æœ¬: {len(result.extracted_text)} å­—ç¬¦")
        except Exception as e:
            logger.error(f"  âŒ æ–‡æœ¬æå–å¤±è´¥: {e}")
            result.errors.append(f"æ–‡æœ¬æå–å¤±è´¥: {e}")

        # Layer 3: è§†é¢‘å¢å¼ºåˆ†æï¼ˆå¯é€‰ï¼‰
        if source_type == "video" and cfg.VIDEO_ANALYSIS_LEVEL != "off":
            try:
                result.video_analysis = self._analyze_video(file_path)
                logger.info(f"  ğŸ¬ è§†é¢‘åˆ†æå®Œæˆ")
            except Exception as e:
                logger.error(f"  âŒ è§†é¢‘åˆ†æå¤±è´¥: {e}")
                result.errors.append(f"è§†é¢‘åˆ†æå¤±è´¥: {e}")

        # Layer 4: AI åˆ†æå±‚ â€” ç»“æ„åŒ–æç‚¼
        if result.extracted_text:
            try:
                result.ai_result = self._ai_analyze(result.extracted_text, result.video_analysis)
                logger.info(f"  ğŸ§  AI æç‚¼å®Œæˆ")
            except Exception as e:
                logger.error(f"  âŒ AI æç‚¼å¤±è´¥: {e}")
                result.errors.append(f"AI æç‚¼å¤±è´¥: {e}")

        # Layer 5: èåˆè¾“å‡ºå±‚
        try:
            result.output_path = self._generate_output(result)
            logger.info(f"  ğŸ“„ è¾“å‡º: {result.output_path}")
        except Exception as e:
            logger.error(f"  âŒ è¾“å‡ºç”Ÿæˆå¤±è´¥: {e}")
            result.errors.append(f"è¾“å‡ºç”Ÿæˆå¤±è´¥: {e}")

        result.processing_time_sec = round(time.time() - start, 2)
        logger.info(f"âœ… å®Œæˆ: {file_path.name} ({result.processing_time_sec}s)")

        return result

    def _identify_type(self, file_path: Path) -> str | None:
        """Layer 1: è¯†åˆ«æ–‡ä»¶ç±»å‹"""
        from .ingestion.router import identify_file_type
        return identify_file_type(file_path)

    def _extract_content(self, file_path: Path, source_type: str) -> str:
        """Layer 2: æå–æ–‡æœ¬å†…å®¹"""
        from .processing import extract_text
        return extract_text(file_path, source_type)

    def _analyze_video(self, file_path: Path) -> dict:
        """Layer 3: è§†é¢‘å¢å¼ºåˆ†æ"""
        from .video_analysis import analyze_video
        return analyze_video(file_path)

    def _ai_analyze(self, text: str, video_analysis: dict | None = None) -> dict:
        """Layer 4: AI ç»“æ„åŒ–æç‚¼"""
        from .ai_analysis.extractor import extract_knowledge
        return extract_knowledge(text, video_analysis)

    def _generate_output(self, result: ProcessingResult) -> str:
        """Layer 5: ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        from .fusion import generate_output
        return generate_output(result, self.output_dir, self.output_format)
