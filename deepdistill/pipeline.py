"""
DeepDistill ä¸»ç®¡çº¿ç¼–æ’
åè°ƒ 6 å±‚å¤„ç†æµç¨‹ï¼šè¾“å…¥ â†’ å†…å®¹å¤„ç† â†’ è§†é¢‘/å›¾ç‰‡é£æ ¼åˆ†æ â†’ AI æç‚¼ â†’ èåˆè¾“å‡º â†’ çŸ¥è¯†ç®¡ç†

æ ¸å¿ƒè®¾è®¡ï¼š
- æ¯ä¸€å±‚çš„è¾“å‡ºæ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œå±‚é—´é€šè¿‡ PipelineResult ä¼ é€’
- æ’ä»¶åŒ–ï¼šæ¯ä¸ªå¤„ç†å™¨å®ç°ç»Ÿä¸€æ¥å£ï¼Œå¯ç‹¬ç«‹æ›¿æ¢
- æ¸è¿›å¢å¼ºï¼šMVP åªéœ€ Layer 1-2-4-5
- intent å‚æ•°æ§åˆ¶å¤„ç†è·¯å¾„ï¼šcontentï¼ˆæå–å†…å®¹ï¼‰/ styleï¼ˆåˆ†æé£æ ¼ï¼‰
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

from .config import cfg

logger = logging.getLogger("deepdistill.pipeline")


@dataclass
class ProcessingResult:
    """ç®¡çº¿å¤„ç†ç»“æœ"""
    source_path: str
    source_type: str  # video/audio/image/document/webpage
    filename: str

    # Layer 2: æå–çš„æ–‡æœ¬
    extracted_text: str = ""

    # Layer 3: è§†é¢‘åˆ†æï¼ˆå¯é€‰ï¼Œintent=style æ—¶å¯ç”¨ï¼‰
    video_analysis: dict | None = None

    # Layer 3b: å›¾ç‰‡é£æ ¼åˆ†æï¼ˆå¯é€‰ï¼Œintent=style ä¸” image ç±»å‹æ—¶å¯ç”¨ï¼‰
    image_style: dict | None = None

    # Layer 4: AI æç‚¼ç»“æœ
    ai_result: dict | None = None

    # Layer 5: è¾“å‡ºè·¯å¾„
    output_path: str = ""

    # Layer 5.5: è§†è§‰ç´ æ
    visual_assets: dict | None = None

    # å¤„ç†æ„å›¾ä¸æ–‡æ¡£ç±»å‹ï¼ˆç”¨äºæ¨¡æ¿ä¸å¯¼å‡ºæ ·å¼ç»†åˆ†ï¼‰
    intent: str = "content"
    doc_type: str = "doc"  # "doc" | "skill" | "both"

    # å…ƒæ•°æ®
    processing_time_sec: float = 0.0
    created_at: str = ""
    errors: list[str] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "source_path": self.source_path,
            "source_type": self.source_type,
            "filename": self.filename,
            "extracted_text_length": len(self.extracted_text),
            "raw_text": self.extracted_text or "",
            "extracted_text": self.extracted_text or "",
            "has_video_analysis": self.video_analysis is not None,
            "video_analysis": self.video_analysis,
            "image_style": self.image_style,
            "ai_result": self.ai_result,
            "visual_assets": self.visual_assets,
            "output_path": self.output_path,
            "intent": self.intent,
            "doc_type": getattr(self, "doc_type", "doc"),
            "processing_time_sec": self.processing_time_sec,
            "created_at": self.created_at,
            "errors": self.errors,
        }


class Pipeline:
    """ä¸»ç®¡çº¿ï¼šåè°ƒå„å±‚å¤„ç†å™¨ï¼Œæ ¹æ® intent èµ°ä¸åŒè·¯å¾„"""

    # å„å±‚è¿›åº¦åŒºé—´å®šä¹‰ï¼ˆç™¾åˆ†æ¯”ï¼‰
    PROGRESS_STEPS = {
        "identify":  {"start": 5,  "end": 10,  "label": "è¯†åˆ«æ–‡ä»¶æ ¼å¼"},
        "extract":   {"start": 10, "end": 35,  "label": "æå–æ–‡æœ¬å†…å®¹"},
        "style":     {"start": 35, "end": 55,  "label": "åˆ†æé£æ ¼ç‰¹å¾"},
        "ai":        {"start": 55, "end": 80,  "label": "AI ç»“æ„åŒ–æç‚¼"},
        "output":    {"start": 80, "end": 90,  "label": "ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"},
        "visual":    {"start": 90, "end": 95,  "label": "ç”Ÿæˆè§†è§‰ç´ æ"},
        "done":      {"start": 95, "end": 100, "label": "å¤„ç†å®Œæˆ"},
    }

    def __init__(
        self,
        output_dir: Path | None = None,
        output_format: str | None = None,
        intent: str = "content",
        doc_type: str = "doc",
        progress_callback: Optional[callable] = None,
    ):
        self.output_dir = output_dir or cfg.OUTPUT_DIR
        self.output_format = output_format or cfg.OUTPUT_FORMAT
        self.intent = intent  # "content" | "style"
        self.doc_type = doc_type  # "doc" | "skill" | "both"ï¼ˆç”¨äºæ¨¡æ¿ä¸å¯¼å‡ºæ ·å¼ç»†åˆ†ï¼‰
        self._progress_cb = progress_callback  # è¿›åº¦å›è°ƒï¼š(percent, step_label) -> None
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _report_progress(self, step: str, sub_progress: float = 0.0):
        """æŠ¥å‘Šè¿›åº¦ã€‚sub_progress ä¸ºå½“å‰æ­¥éª¤å†…çš„å®Œæˆæ¯”ä¾‹ 0.0~1.0"""
        if not self._progress_cb:
            return
        info = self.PROGRESS_STEPS.get(step)
        if not info:
            return
        span = info["end"] - info["start"]
        pct = int(info["start"] + span * min(sub_progress, 1.0))
        try:
            self._progress_cb(pct, info["label"])
        except Exception:
            pass  # å›è°ƒå¤±è´¥ä¸å½±å“ç®¡çº¿

    def process(self, file_path: Path) -> ProcessingResult | None:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œæ ¹æ® intent èµ°ä¸åŒè·¯å¾„"""
        import time
        start = time.time()

        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†: {file_path.name} (intent={self.intent})")

        # Layer 1: è¾“å…¥å±‚ â€” æ ¼å¼è¯†åˆ«
        self._report_progress("identify", 0.0)
        source_type = self._identify_type(file_path)
        if not source_type:
            logger.warning(f"âš ï¸  ä¸æ”¯æŒçš„æ ¼å¼: {file_path.suffix}")
            return None
        self._report_progress("identify", 1.0)

        result = ProcessingResult(
            source_path=str(file_path),
            source_type=source_type,
            filename=file_path.name,
            intent=self.intent,
            doc_type=getattr(self, "doc_type", "doc"),
            created_at=datetime.now(timezone.utc).isoformat(),
        )

        # Layer 2: å†…å®¹å¤„ç†å±‚ â€” æ–‡æœ¬æå–ï¼ˆä¸¤æ¡è·¯å¾„éƒ½éœ€è¦ï¼‰
        self._report_progress("extract", 0.0)
        try:
            result.extracted_text = self._extract_content(file_path, source_type)
            logger.info(f"  ğŸ“ æå–æ–‡æœ¬: {len(result.extracted_text)} å­—ç¬¦")
        except Exception as e:
            logger.error(f"  âŒ æ–‡æœ¬æå–å¤±è´¥: {e}")
            result.errors.append(f"æ–‡æœ¬æå–å¤±è´¥: {e}")
        self._report_progress("extract", 1.0)

        # Layer 3: é£æ ¼åˆ†æï¼ˆä»… intent=style æ—¶æ‰§è¡Œï¼‰
        if self.intent == "style":
            self._report_progress("style", 0.0)
            # è§†é¢‘é£æ ¼åˆ†æ
            if source_type == "video" and cfg.VIDEO_ANALYSIS_LEVEL != "off":
                try:
                    result.video_analysis = self._analyze_video(file_path)
                    logger.info(f"  ğŸ¬ è§†é¢‘é£æ ¼åˆ†æå®Œæˆ")
                except Exception as e:
                    logger.error(f"  âŒ è§†é¢‘é£æ ¼åˆ†æå¤±è´¥: {e}")
                    result.errors.append(f"è§†é¢‘é£æ ¼åˆ†æå¤±è´¥: {e}")

            # å›¾ç‰‡é£æ ¼åˆ†æ
            if source_type == "image":
                try:
                    result.image_style = self._analyze_image_style(file_path)
                    logger.info(f"  ğŸ¨ å›¾ç‰‡é£æ ¼åˆ†æå®Œæˆ")
                except Exception as e:
                    logger.error(f"  âŒ å›¾ç‰‡é£æ ¼åˆ†æå¤±è´¥: {e}")
                    result.errors.append(f"å›¾ç‰‡é£æ ¼åˆ†æå¤±è´¥: {e}")
            self._report_progress("style", 1.0)
        else:
            # è·³è¿‡é£æ ¼åˆ†æï¼Œç›´æ¥æ¨è¿›è¿›åº¦
            self._report_progress("style", 1.0)

        # Layer 4: AI åˆ†æå±‚ â€” ç»“æ„åŒ–æç‚¼
        self._report_progress("ai", 0.0)
        if result.extracted_text or result.video_analysis or result.image_style:
            try:
                result.ai_result = self._ai_analyze(
                    result.extracted_text,
                    result.video_analysis,
                    result.image_style,
                )
                logger.info(f"  ğŸ§  AI æç‚¼å®Œæˆ")
            except Exception as e:
                logger.error(f"  âŒ AI æç‚¼å¤±è´¥: {e}")
                result.errors.append(f"AI æç‚¼å¤±è´¥: {e}")
        self._report_progress("ai", 1.0)

        # Layer 5: èåˆè¾“å‡ºå±‚
        self._report_progress("output", 0.0)
        try:
            result.output_path = self._generate_output(result)
            logger.info(f"  ğŸ“„ è¾“å‡º: {result.output_path}")
        except Exception as e:
            logger.error(f"  âŒ è¾“å‡ºç”Ÿæˆå¤±è´¥: {e}")
            result.errors.append(f"è¾“å‡ºç”Ÿæˆå¤±è´¥: {e}")
        self._report_progress("output", 1.0)

        # Layer 5.5: è§†è§‰ç´ æç”Ÿæˆï¼ˆå·²ç§»é™¤ â€” Stable Diffusion ä¸å†é›†æˆï¼‰
        self._report_progress("visual", 1.0)

        result.processing_time_sec = round(time.time() - start, 2)
        self._report_progress("done", 1.0)
        logger.info(f"âœ… å®Œæˆ: {file_path.name} ({result.processing_time_sec}s)")

        return result

    def _identify_type(self, file_path: Path) -> str | None:
        """Layer 1: è¯†åˆ«æ–‡ä»¶ç±»å‹"""
        from .ingestion.router import identify_file_type
        return identify_file_type(file_path)

    def _extract_content(self, file_path: Path, source_type: str) -> str:
        """Layer 2: æå–æ–‡æœ¬å†…å®¹"""
        from .processing import extract_text
        return extract_text(file_path, source_type)

    def _analyze_video(self, file_path: Path) -> dict:
        """Layer 3: è§†é¢‘å¢å¼ºåˆ†æ"""
        from .video_analysis import analyze_video
        return analyze_video(file_path)

    def _analyze_image_style(self, file_path: Path) -> dict:
        """Layer 3b: å›¾ç‰‡é£æ ¼åˆ†æ"""
        from .processing.image_style import analyze_image_style
        return analyze_image_style(file_path)

    def _ai_analyze(
        self,
        text: str,
        video_analysis: dict | None = None,
        image_style: dict | None = None,
    ) -> dict:
        """Layer 4: AI ç»“æ„åŒ–æç‚¼ã€‚ä»…ä¸¤æ¨¡æ¿ï¼šsummarize / style_analysisï¼›Skill æ–‡æ¡£ç”¨ summarize+hintã€‚"""
        from .ai_analysis.extractor import extract_knowledge, resolve_prompt_template
        template_name = resolve_prompt_template(self.intent, getattr(self, "doc_type", "doc"))
        doc_type = getattr(self, "doc_type", "doc")
        hint = None
        if self.intent == "content" and doc_type in ("skill", "both"):
            hint = "æœ¬è¾“å‡ºå°†ç”¨äº Skill æ–‡æ¡£ï¼Œè¯·å°½é‡è¡¥å…… rulesï¼ˆè§„åˆ™/çº¦æŸï¼‰ã€stepsï¼ˆå®è·µæ­¥éª¤ï¼Œæ¯é¡¹å« step_number, title, summaryï¼‰åŠ relatedï¼ˆå…³è”çŸ¥è¯†ï¼‰ã€‚"
        style_context = video_analysis
        if image_style:
            style_context = image_style if not video_analysis else {
                **video_analysis, "image_style": image_style
            }
        return extract_knowledge(text, style_context, template_name=template_name, hint=hint)

    def _generate_output(self, result: ProcessingResult) -> str:
        """Layer 5: ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        from .fusion import generate_output
        return generate_output(result, self.output_dir, self.output_format)

    def _generate_visuals(self, result: ProcessingResult) -> dict:
        """Layer 5.5: ç”Ÿæˆè§†è§‰ç´ æï¼ˆprompt + å¯é€‰å›¾ç‰‡ï¼‰"""
        from .fusion.visual_generator import generate_visual_assets
        visual_dir = self.output_dir / "visuals"
        return generate_visual_assets(
            ai_result=result.ai_result,
            video_analysis=result.video_analysis,
            output_dir=visual_dir,
        )
